# CH03 회귀 알고리즘과 모델 규제
## 03-1. K-최근접 이웃 회귀
### 1. 핵심 개념
- 회귀: 임의의 수치(타깃값)를 예측하는 문제
- k-최근접 이웃 회귀: 가장 가까운 이웃 샘플을 찾고, 이 샘플들의 타깃값을 평균하여 예측으로 삼음
- 결정계수(R^2): 회귀 문제 성능 측정 도구, 1에 가까울수록 좋은 모델
- 과대적합: 모델의 훈련 세트 성능이 테스트 세트 성능보다 훨씬 좋은 경우
- 과소적합: 훈련 세트와 테스트 세트 성능이 모두 동일하게 낮거나, 테스트 세트 성능이 훈련 세트 성능보다 높은 경우
### 2. 핵심 패키지와 함수
- scikit-learn
  - KNeighborsRegressor: k-최근접 이웃 회귀 모델을 만드는 사이킷런 클래스
    - n_neighbors 매개변수로 이웃의 개수 지정(기본값 5)
  - mean_absolute_error(): 회귀 모델의 평균 절댓값 오차를 계산
    - 첫 번째 매개변수는 타깃, 두 번째 매개변수는 예측값 전달
    - 비슷한 함수로 평균 제곱 오차를 계산하는 mean_squared_error()가 있음
- numpy
  - reshape(): 배열의 크기를 바꾸는 메서드
    - 바꾸고자하는 배열의 크기를 매개변수로 전달
## 03-2. 선형 회귀
### 1. 핵심 개념
- 선형 회귀: 특성과 타깃 사이의 관계를 가장 잘 나타내는 선형 방정식을 찾음, 특성이 하나면 직선 방정식
  - 선형 회귀가 찾은 특성과 타깃 사이의 관계는 선형 방정식의 계수 또는 가중치에 저장됨
- 모델 파라미터: 선형 회귀가 찾은 가중치처럼 머신러닝 모델이 특성에서 학습한 파라미터를 말함
- 다항 회귀: 다항식을 사용하여 특성과 타깃 사이의 관계를 나타냄
### 2. 핵심 패키지와 함수
- scikit-learn
  - LinearRegression: 사이킷런의 선형 회귀 클래스
    - fit_intercept=False로 하면 절편을 학습하지 않음(기본값 True)
    - coef_ 속성은 특성에 대한 계수를 포함한 배열(배열의 크기=특성의 개수)
    - intercept_ 속정은 절편이 저장됨
## 03-3. 특성 공학과 규제
### 1. 핵심 개념
- 다중 회귀: 여러 개의 특성을 사용하는 회귀 모델
- 특성 공학: 주어진 특성을 조합하여 새로운 특성을 만드는 일련의 작업 과정
- 릿지: 규제가 있는 선형 모델 중 하나이며, 선형 모델의 계수를 작게 만들어 과대적합을 완화
- 라쏘: 규제가 있는 선형 모델 중 하나이며, 릿지와 달리 계수 값을 아예 0으로 만들 수 있음
- 하이퍼파라미터: 머신러닝 알고리즘이 학습하지 않는 파라미터
  - 릿지와 라쏘의 규제 강도 alpha 파라미터
### 2. 핵심 패키지와 함수
- pandas
  - read_csv(): CSV 파일을 로컬 컴퓨터나 인터넷에서 읽어 판다스 데이터프레임으로 변환하는 메소드
- scikit-learn
  - PolynomialFeature: 주어진 특성을 조합하여 새로운 특성을 만드는 클래스
    - degree는 최고 차수를 지정(기본값은 2)
    - interaction_only=True이면 거듭제곱 항은 제외되고 특성 간의 곱셈 항만 추가됨(기본값은 False)
    - include_bias=False이면 절편을 위한 특성을 추가하지 않음(기본값은 True)
  - Rigde: 규제가 있는 회귀 알고리즘인 릿지 회귀 모델을 훈련하는 메소드
    - alpha 매개변수로 규제의 강도 조절, alpha 값이 클수록 규제가 세짐(기본값은 1)
    - solver 매개변수에 최적의 모델을 찾기 위한 방법을 지정(기본값은 'auto')
      - sag: 확률적 평균 경사하강법 알고리즘
  - Lasso: 규제가 있는 회귀 알고리즘인 라쏘 회귀 모델을 훈련하는 메소드
    - 최적 모델을 찾기 위해 좌표축을 따라 최적화를 수행해가는 좌표하강법을 사용
    - alpha와 random_state 매개변수는 Ridge 클래스와 동일
    - max_iter은 알고리즘의 수행 반복 횟수를 지정(기본값은 1000)
